# PDF Spider Crawler

PDF Spider Crawler is a Python web scraping tool built using Scrapy that allows you to extract PDF links from university or from normal websites. This tool is designed to make it easier for you to gather PDF links from various university websites in a structured manner. 

## Features
- Scrapes PDF links from university websites.
- Allows customization of scraping depth and user agent.
- Outputs the extracted links in JSON format.

## Installation

1. Clone the repository:
   ```
   git clone https://github.com/your-username/pdf-spider-crawler.git
   cd pdf-spider-crawler
    ```

2. Install the dependencies:
    ```
    pip install -r requirements.txt
    ```
3. Run the crawler:
    ```
    python pdf_spider.py
    ```
4. The extracted links will be saved in `output.json` file.
